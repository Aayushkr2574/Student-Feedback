{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47d68ec2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Text Classification With BERT and KerasNLP\n",
    "\n",
    "Now since I am done building the sentiment analysis model using different algorithms, I will make use of BERT, a popular Masked Language Model which is bidirectional (it has access to the words left and right) to build a the text classification model and also KerasNLP, which provides a simple Keras API for training and finetuning NLP models to classify the sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c980e54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T08:54:47.232367Z",
     "iopub.status.busy": "2023-09-27T08:54:47.231978Z",
     "iopub.status.idle": "2023-09-27T08:55:04.821399Z",
     "shell.execute_reply": "2023-09-27T08:55:04.819913Z",
     "shell.execute_reply.started": "2023-09-27T08:54:47.232337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "# import the required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import zipfile\n",
    "import os\n",
    "import string\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_nlp\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fe82c0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T08:55:04.823719Z",
     "iopub.status.busy": "2023-09-27T08:55:04.823111Z",
     "iopub.status.idle": "2023-09-27T08:55:04.844854Z",
     "shell.execute_reply": "2023-09-27T08:55:04.843707Z",
     "shell.execute_reply.started": "2023-09-27T08:55:04.823690Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the exported data\n",
    "df1 = pd.read_csv('/kaggle/input/sentiments/exported_sentiments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96bb6939",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T08:55:04.846463Z",
     "iopub.status.busy": "2023-09-27T08:55:04.846059Z",
     "iopub.status.idle": "2023-09-27T08:55:04.870701Z",
     "shell.execute_reply": "2023-09-27T08:55:04.869249Z",
     "shell.execute_reply.started": "2023-09-27T08:55:04.846429Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiments\n",
       "0    59\n",
       "1    41\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode the target labels\n",
    "df1['Sentiments'] = df1['Sentiments'].replace({\n",
    "    'negative': 0,\n",
    "    'positive': 1\n",
    "})\n",
    "df1['Sentiments'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eefb200e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T08:55:04.874541Z",
     "iopub.status.busy": "2023-09-27T08:55:04.874141Z",
     "iopub.status.idle": "2023-09-27T08:55:04.883712Z",
     "shell.execute_reply": "2023-09-27T08:55:04.882637Z",
     "shell.execute_reply.started": "2023-09-27T08:55:04.874504Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df1['Feedback']\n",
    "y = df1['Sentiments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53c1886e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T08:55:04.886359Z",
     "iopub.status.busy": "2023-09-27T08:55:04.885927Z",
     "iopub.status.idle": "2023-09-27T08:55:04.913472Z",
     "shell.execute_reply": "2023-09-27T08:55:04.912159Z",
     "shell.execute_reply.started": "2023-09-27T08:55:04.886327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1\n",
      "1     1\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "     ..\n",
      "95    1\n",
      "96    0\n",
      "97    0\n",
      "98    1\n",
      "99    1\n",
      "Name: Sentiments, Length: 100, dtype: int64\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The man is too fast in his teaching,he clearly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The class is dry but he really puts in efforts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The course is shit and it's a threat to my bra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He no try at all, didn’t teach well.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ogbeni you sef know as e dae go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>easy and no wahala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>terrible way of teaching with the I-dont-care ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>do not like coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>this practical is hard on top 1 unit course haba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>not the right way to teach, Mr Akanni</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Feedback\n",
       "0   The man is too fast in his teaching,he clearly...\n",
       "1      The class is dry but he really puts in efforts\n",
       "2   The course is shit and it's a threat to my bra...\n",
       "3                He no try at all, didn’t teach well.\n",
       "4                    Ogbeni you sef know as e dae go \n",
       "..                                                ...\n",
       "95                                 easy and no wahala\n",
       "96  terrible way of teaching with the I-dont-care ...\n",
       "97                                 do not like coding\n",
       "98   this practical is hard on top 1 unit course haba\n",
       "99              not the right way to teach, Mr Akanni\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y)\n",
    "print()\n",
    "X.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d368dbd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T08:55:04.915571Z",
     "iopub.status.busy": "2023-09-27T08:55:04.915260Z",
     "iopub.status.idle": "2023-09-27T08:55:05.478511Z",
     "shell.execute_reply": "2023-09-27T08:55:05.477397Z",
     "shell.execute_reply.started": "2023-09-27T08:55:04.915546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /usr/share/nltk_data/corpora/wordnet.zip\n",
      "   creating: /usr/share/nltk_data/corpora/wordnet/\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/README  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \n"
     ]
    }
   ],
   "source": [
    "!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "974916ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T08:55:05.480367Z",
     "iopub.status.busy": "2023-09-27T08:55:05.480027Z",
     "iopub.status.idle": "2023-09-27T08:55:06.919370Z",
     "shell.execute_reply": "2023-09-27T08:55:06.918347Z",
     "shell.execute_reply.started": "2023-09-27T08:55:05.480342Z"
    }
   },
   "outputs": [],
   "source": [
    "# Text Preprocessing of the texts column using NLTK\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+|@\\w+|#\\w+\", \"\", text)\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    text = re.sub(r'\\b[0-9]+\\b\\s*', '', text)\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "X_preprocessed = [preprocess_text(text) for text in X]\n",
    "\n",
    "# Split the preprocessed data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02c3c710",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T08:55:06.922699Z",
     "iopub.status.busy": "2023-09-27T08:55:06.922030Z",
     "iopub.status.idle": "2023-09-27T08:55:06.929501Z",
     "shell.execute_reply": "2023-09-27T08:55:06.928136Z",
     "shell.execute_reply.started": "2023-09-27T08:55:06.922667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75,) (75,)\n",
      "(25,) (25,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pd.Series(X_preprocessed), y, test_size=0.25)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bbcaeb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T08:55:06.931136Z",
     "iopub.status.busy": "2023-09-27T08:55:06.930804Z",
     "iopub.status.idle": "2023-09-27T08:55:06.943512Z",
     "shell.execute_reply": "2023-09-27T08:55:06.942390Z",
     "shell.execute_reply.started": "2023-09-27T08:55:06.931108Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert labels to one-hot encoded format\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=2, dtype='float32')\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=2, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57b5aa28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T08:55:06.948153Z",
     "iopub.status.busy": "2023-09-27T08:55:06.947783Z",
     "iopub.status.idle": "2023-09-27T08:55:11.145700Z",
     "shell.execute_reply": "2023-09-27T08:55:11.144832Z",
     "shell.execute_reply.started": "2023-09-27T08:55:06.948125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-nlp/models/bert_tiny_en_uncased_sst2/v1/vocab.txt\n",
      "231508/231508 [==============================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/keras-nlp/models/bert_tiny_en_uncased_sst2/v1/model.h5\n",
      "17596448/17596448 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# load the pretrained BERT model that has been finetuned for sentiment analysis\n",
    "\n",
    "model_name = \"bert_tiny_en_uncased_sst2\"\n",
    "classifier = keras_nlp.models.BertClassifier.from_preset(\n",
    "    model_name,\n",
    "    num_classes=2,\n",
    "    load_weights = True,\n",
    "    activation='sigmoid' # for the binary classification task\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484e8097",
   "metadata": {},
   "source": [
    "The next step is to compile and train the model. The aim here is to use the pre-trained model and finetune it on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1b6c5a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T08:55:11.149726Z",
     "iopub.status.busy": "2023-09-27T08:55:11.148856Z",
     "iopub.status.idle": "2023-09-27T08:55:42.754692Z",
     "shell.execute_reply": "2023-09-27T08:55:42.753664Z",
     "shell.execute_reply.started": "2023-09-27T08:55:11.149695Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 26s 10s/step - loss: 0.4940 - accuracy: 0.7600 - val_loss: 0.3557 - val_accuracy: 0.8800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7c6ecf0c60b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.compile(\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    jit_compile=True,\n",
    "     metrics=[\"accuracy\"],\n",
    ")\n",
    "# Access backbone programatically (e.g., to change `trainable`).\n",
    "classifier.backbone.trainable = False\n",
    "# Fit again.\n",
    "classifier.fit(x=X_train, y=y_train, validation_data=(X_test,y_test), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddc512bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T08:55:42.757345Z",
     "iopub.status.busy": "2023-09-27T08:55:42.756148Z",
     "iopub.status.idle": "2023-09-27T08:55:44.987131Z",
     "shell.execute_reply": "2023-09-27T08:55:44.986164Z",
     "shell.execute_reply.started": "2023-09-27T08:55:42.757308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.3557 - accuracy: 0.8800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3557356894016266, 0.8799999952316284]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model on the testing data\n",
    "classifier.evaluate(X_test, y_test,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d419ca8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T09:00:12.399528Z",
     "iopub.status.busy": "2023-09-27T09:00:12.399210Z",
     "iopub.status.idle": "2023-09-27T09:00:14.355494Z",
     "shell.execute_reply": "2023-09-27T09:00:14.354476Z",
     "shell.execute_reply.started": "2023-09-27T09:00:12.399505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 858ms/step\n",
      "love to code and course is about coding. A plus for me:➡ negative with a 81.2 percent confidence.\n",
      "\n",
      "The course is shit and it's a threat to my brain,the teaching mode is so poor :➡ negative with a 93.55 percent confidence.\n",
      "\n",
      "great teaching method from lecturer:➡ negative with a 64.99 percent confidence.\n",
      "\n",
      "nice:➡ positive with a 77.77 percent confidence.\n",
      "\n",
      "this course is hard:➡ negative with a 92.44 percent confidence.\n",
      "\n",
      "He no try at all, didn’t teach well.:➡ negative with a 84.03 percent confidence.\n",
      "\n",
      "Akanni, you are a bad teacher wtf:➡ negative with a 93.4 percent confidence.\n",
      "\n",
      "I just hope I pass this course cos omo:➡ negative with a 91.12 percent confidence.\n",
      "\n",
      "I struggled at the start but it all went easy as time goes by:➡ negative with a 81.65 percent confidence.\n",
      "\n",
      "The teaching mode is okay as the lecturer do revision of what's being taught from time to time.:➡ negative with a 80.12 percent confidence.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking the model to see performance on new samples\n",
    "sentiment_categories = [\"negative\", \"positive\"]\n",
    "\n",
    "new_examples = list(df1['Feedback'].sample(10))\n",
    "\n",
    "scores = classifier.predict([preprocess_text(example) for example in new_examples])\n",
    "\n",
    "for i, score in enumerate(scores):\n",
    "    print(f\"{new_examples[i]}:➡ {sentiment_categories[np.argmax(score)]} with a { (100 * np.max(score)).round(2) } percent confidence.\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d771951",
   "metadata": {},
   "source": [
    "### Improving model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f3f2d44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T09:00:18.823533Z",
     "iopub.status.busy": "2023-09-27T09:00:18.823008Z",
     "iopub.status.idle": "2023-09-27T09:00:41.250575Z",
     "shell.execute_reply": "2023-09-27T09:00:41.249383Z",
     "shell.execute_reply.started": "2023-09-27T09:00:18.823498Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 12s 2s/step - loss: 0.4955 - accuracy: 0.7467 - val_loss: 0.3510 - val_accuracy: 0.9200 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7c6ea8a22950>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Define a learning rate scheduler\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "\n",
    "# During model fitting\n",
    "classifier.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), batch_size=32, callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50d6c47e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T09:00:41.252300Z",
     "iopub.status.busy": "2023-09-27T09:00:41.252027Z",
     "iopub.status.idle": "2023-09-27T09:00:43.489976Z",
     "shell.execute_reply": "2023-09-27T09:00:43.488210Z",
     "shell.execute_reply.started": "2023-09-27T09:00:41.252280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.3510 - accuracy: 0.9200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3510168194770813, 0.9200000166893005]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model on the testing data\n",
    "classifier.evaluate(X_test, y_test,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfcba50b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T09:00:58.222683Z",
     "iopub.status.busy": "2023-09-27T09:00:58.222287Z",
     "iopub.status.idle": "2023-09-27T09:01:00.175874Z",
     "shell.execute_reply": "2023-09-27T09:01:00.174006Z",
     "shell.execute_reply.started": "2023-09-27T09:00:58.222652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 857ms/step\n",
      "Omooooo is all I can say😭:➡ negative with a 78.77 percent confidence.\n",
      "\n",
      "good one:➡ positive with a 87.95 percent confidence.\n",
      "\n",
      "Teaching mode is bad but course is sometimes easy to understand:➡ negative with a 77.9 percent confidence.\n",
      "\n",
      "I learnt a lot in the course, but the lecturers are too demanding:➡ negative with a 68.98 percent confidence.\n",
      "\n",
      "hard and lecturer is fast when teaching:➡ negative with a 53.13 percent confidence.\n",
      "\n",
      "The lecturer is good and his course is also good:➡ positive with a 82.27 percent confidence.\n",
      "\n",
      "do not like coding:➡ negative with a 78.99 percent confidence.\n",
      "\n",
      "The course is very very difficult and the lecturer no dey even make am easy.\n",
      "He actually taught and explained 27 pages of the material within 3 hours.:➡ negative with a 75.1 percent confidence.\n",
      "\n",
      "love to code:➡ positive with a 89.35 percent confidence.\n",
      "\n",
      "The outline of the course is difficult and lecturer is bad:➡ negative with a 85.93 percent confidence.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking the model to see performance on new samples\n",
    "sentiment_categories = [\"negative\", \"positive\"]\n",
    "\n",
    "new_examples = list(df1['Feedback'].sample(10))\n",
    "\n",
    "scores = classifier.predict([preprocess_text(example) for example in new_examples])\n",
    "\n",
    "for i, score in enumerate(scores):\n",
    "    print(f\"{new_examples[i]}:➡ {sentiment_categories[np.argmax(score)]} with a { (100 * np.max(score)).round(2) } percent confidence.\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "455b27bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set some layers of the BERT backbone to trainable\n",
    "# classifier.backbone.layers[-3:].trainable = True\n",
    "\n",
    "# # Compile and fit the model again\n",
    "# classifier.compile(\n",
    "#     loss=keras.losses.BinaryCrossentropy(),\n",
    "#     optimizer=keras.optimizers.Adam(learning_rate=1e-5),  # Adjust the learning rate\n",
    "#     metrics=[\"accuracy\"]\n",
    "# )\n",
    "# classifier.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), batch_size=32, callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93127f76",
   "metadata": {},
   "source": [
    "## Finetune BERT With User-controlled Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1338ffa0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T09:02:17.903468Z",
     "iopub.status.busy": "2023-09-27T09:02:17.903135Z",
     "iopub.status.idle": "2023-09-27T09:02:18.311162Z",
     "shell.execute_reply": "2023-09-27T09:02:18.310140Z",
     "shell.execute_reply.started": "2023-09-27T09:02:17.903441Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocessor = keras_nlp.models.BertPreprocessor.from_preset(\n",
    "    model_name,\n",
    "    sequence_length=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97d59d62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T09:02:20.423014Z",
     "iopub.status.busy": "2023-09-27T09:02:20.422299Z",
     "iopub.status.idle": "2023-09-27T09:02:22.571437Z",
     "shell.execute_reply": "2023-09-27T09:02:22.569707Z",
     "shell.execute_reply.started": "2023-09-27T09:02:20.422974Z"
    }
   },
   "outputs": [],
   "source": [
    "training_data = tf.data.Dataset.from_tensor_slices(([X_train], [y_train]))\n",
    "validation_data = tf.data.Dataset.from_tensor_slices(([X_test], [y_test]))\n",
    "\n",
    "train_cached = (\n",
    "    training_data.map(preprocessor, tf.data.AUTOTUNE).cache().prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "test_cached = (\n",
    "    validation_data.map(preprocessor, tf.data.AUTOTUNE).cache().prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c14b605",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T09:03:22.562732Z",
     "iopub.status.busy": "2023-09-27T09:03:22.562385Z",
     "iopub.status.idle": "2023-09-27T09:03:44.108189Z",
     "shell.execute_reply": "2023-09-27T09:03:44.106922Z",
     "shell.execute_reply.started": "2023-09-27T09:03:22.562707Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.4932 - accuracy: 0.7867 - val_loss: 0.2439 - val_accuracy: 0.9200\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 1s 829ms/step - loss: 0.4144 - accuracy: 0.7867 - val_loss: 0.2652 - val_accuracy: 0.9200\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 1s 735ms/step - loss: 0.2634 - accuracy: 0.9467 - val_loss: 0.3650 - val_accuracy: 0.8400\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 1s 729ms/step - loss: 0.2165 - accuracy: 0.9467 - val_loss: 0.4359 - val_accuracy: 0.8000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 1s 741ms/step - loss: 0.1604 - accuracy: 0.9733 - val_loss: 0.4072 - val_accuracy: 0.8400\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 1s 738ms/step - loss: 0.1292 - accuracy: 0.9733 - val_loss: 0.3172 - val_accuracy: 0.8400\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 1s 736ms/step - loss: 0.0731 - accuracy: 0.9867 - val_loss: 0.2191 - val_accuracy: 0.9600\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 1s 733ms/step - loss: 0.0861 - accuracy: 0.9733 - val_loss: 0.2011 - val_accuracy: 0.9200\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 1s 732ms/step - loss: 0.0687 - accuracy: 0.9867 - val_loss: 0.2211 - val_accuracy: 0.9200\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 1s 752ms/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.2673 - val_accuracy: 0.8800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7c6e795c20e0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pretrained classifier.\n",
    "classifier2 = keras_nlp.models.BertClassifier.from_preset(\n",
    "    model_name,\n",
    "    preprocessor=None,\n",
    "    num_classes=2,\n",
    "    load_weights = True,\n",
    "    activation='sigmoid'\n",
    ")\n",
    "classifier2.compile(\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    jit_compile=True,\n",
    "     metrics=[\"accuracy\"],\n",
    ")\n",
    "classifier2.fit(train_cached, validation_data=test_cached,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcc92bda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T09:03:05.877803Z",
     "iopub.status.busy": "2023-09-27T09:03:05.877464Z",
     "iopub.status.idle": "2023-09-27T09:03:07.186223Z",
     "shell.execute_reply": "2023-09-27T09:03:07.185163Z",
     "shell.execute_reply.started": "2023-09-27T09:03:05.877780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "neutral:➡ negative with a 98.74 percent confidence.\n",
      "\n",
      "good:➡ positive with a 98.73 percent confidence.\n",
      "\n",
      "easy and no wahala:➡ positive with a 98.73 percent confidence.\n",
      "\n",
      "way to go. Nice job from lecturer:➡ positive with a 98.73 percent confidence.\n",
      "\n",
      "Awful & terrible from both the course and lecturer:➡ negative with a 98.74 percent confidence.\n",
      "\n",
      "this course is hard:➡ negative with a 98.74 percent confidence.\n",
      "\n",
      "thank God for my coding skills  bruh:➡ negative with a 98.74 percent confidence.\n",
      "\n",
      "The lecturer is fucking terrible. With his I-dont-care attitude towards students. The worst lecturer so far.:➡ negative with a 98.73 percent confidence.\n",
      "\n",
      "I hate this course plus the man:➡ negative with a 98.74 percent confidence.\n",
      "\n",
      "the teaching method is so terrible :➡ negative with a 98.74 percent confidence.\n",
      "\n",
      "positive experience:➡ positive with a 98.72 percent confidence.\n",
      "\n",
      "Applied my math's knowledge from 200L for the most part of course:➡ negative with a 98.74 percent confidence.\n",
      "\n",
      "I felt the course was a bit rushed in terms of teaching the course and also the materials were a bit complex to read and understand :➡ negative with a 98.69 percent confidence.\n",
      "\n",
      "The course is cool:➡ positive with a 98.73 percent confidence.\n",
      "\n",
      "hard and lecturer is fast when teaching:➡ negative with a 98.73 percent confidence.\n",
      "\n",
      "The lecturer is good, I like him.:➡ positive with a 98.73 percent confidence.\n",
      "\n",
      "Na me dey make the class funny pass even though the man go do him best make am dry.:➡ positive with a 98.72 percent confidence.\n",
      "\n",
      "That man no good at all:➡ positive with a 98.73 percent confidence.\n",
      "\n",
      "relatively easy:➡ positive with a 98.73 percent confidence.\n",
      "\n",
      "The course isn’t supposed to be this difficult if the lecturer had taken his time to explain it and made the class an interactive one. :➡ negative with a 98.73 percent confidence.\n",
      "\n",
      "terrible way of teaching with the I-dont-care attitude:➡ negative with a 98.74 percent confidence.\n",
      "\n",
      "Ogbeni you sef know as e dae go :➡ negative with a 98.74 percent confidence.\n",
      "\n",
      "practicals were okay for me sha:➡ positive with a 98.72 percent confidence.\n",
      "\n",
      "good one:➡ positive with a 98.73 percent confidence.\n",
      "\n",
      "The man is too fast in his teaching,he clearly doesn't know how to teach students very well.:➡ positive with a 98.72 percent confidence.\n",
      "\n",
      "Such a terrible teaching method from the lecturer.:➡ negative with a 98.74 percent confidence.\n",
      "\n",
      "The course is shit and it's a threat to my brain,the teaching mode is so poor :➡ negative with a 98.73 percent confidence.\n",
      "\n",
      "This one-unit course has got a hell of wahala:➡ negative with a 98.61 percent confidence.\n",
      "\n",
      "The course is very very difficult and the lecturer no dey even make am easy.\n",
      "He actually taught and explained 27 pages of the material within 3 hours.:➡ negative with a 98.72 percent confidence.\n",
      "\n",
      "nice:➡ positive with a 98.73 percent confidence.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking the model to see performance on new samples\n",
    "sentiment_categories = [\"negative\", \"positive\"]\n",
    "\n",
    "new_examples = list(df1['Feedback'].sample(30))\n",
    "\n",
    "test_data =  preprocessor([preprocess_text(example) for example in new_examples])\n",
    "scores = classifier2.predict(test_data)\n",
    "\n",
    "for i, score in enumerate(scores):\n",
    "    print(f\"{new_examples[i]}:➡ {sentiment_categories[np.argmax(score)]} with a { (100 * np.max(score)).round(2) } percent confidence.\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53949462",
   "metadata": {},
   "source": [
    "## Saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7b8eb15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T09:06:28.864387Z",
     "iopub.status.busy": "2023-09-27T09:06:28.863963Z",
     "iopub.status.idle": "2023-09-27T09:06:44.344054Z",
     "shell.execute_reply": "2023-09-27T09:06:44.342368Z",
     "shell.execute_reply.started": "2023-09-27T09:06:28.864356Z"
    }
   },
   "outputs": [],
   "source": [
    "# first model\n",
    "classifier.save(\"sentiment_model1\", save_format='tf')\n",
    "\n",
    "# second model\n",
    "classifier2.save(\"sentiment_model2\", save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0fcf9b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T09:20:11.650817Z",
     "iopub.status.busy": "2023-09-27T09:20:11.650425Z",
     "iopub.status.idle": "2023-09-27T09:20:27.492168Z",
     "shell.execute_reply": "2023-09-27T09:20:27.490712Z",
     "shell.execute_reply.started": "2023-09-27T09:20:11.650788Z"
    }
   },
   "outputs": [],
   "source": [
    "# first model\n",
    "classifier.save(\"keras1\", save_format='keras')\n",
    "\n",
    "# second model\n",
    "classifier2.save(\"keras2\", save_format='keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76110ca4",
   "metadata": {},
   "source": [
    "## Download saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b53ae0c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T09:43:44.876154Z",
     "iopub.status.busy": "2023-09-27T09:43:44.875700Z",
     "iopub.status.idle": "2023-09-27T09:43:45.032303Z",
     "shell.execute_reply": "2023-09-27T09:43:45.030713Z",
     "shell.execute_reply.started": "2023-09-27T09:43:44.876115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zip file created: /kaggle/working/keras1.zip\n"
     ]
    }
   ],
   "source": [
    "directory_to_zip = \"/kaggle/working/keras1\"\n",
    "output_zip_file = \"/kaggle/working/keras1.zip\"\n",
    "\n",
    "# Create a Zip file\n",
    "with zipfile.ZipFile(output_zip_file, 'w') as zipf:\n",
    "    for root, dirs, files in os.walk(directory_to_zip):\n",
    "        for file in files:\n",
    "            zipf.write(os.path.join(root, file))\n",
    "            \n",
    "print(f\"Zip file created: {output_zip_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee6e5070",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T09:48:13.603270Z",
     "iopub.status.busy": "2023-09-27T09:48:13.602915Z",
     "iopub.status.idle": "2023-09-27T09:48:13.744858Z",
     "shell.execute_reply": "2023-09-27T09:48:13.743014Z",
     "shell.execute_reply.started": "2023-09-27T09:48:13.603246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zip file created: /kaggle/working/keras2.zip\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "directory_to_zip = \"/kaggle/working/keras2\"\n",
    "output_zip_file = \"/kaggle/working/keras2.zip\"\n",
    "\n",
    "# Create a Zip file\n",
    "with zipfile.ZipFile(output_zip_file, 'w') as zipf:\n",
    "    for root, dirs, files in os.walk(directory_to_zip):\n",
    "        for file in files:\n",
    "            zipf.write(os.path.join(root, file))\n",
    "            \n",
    "print(f\"Zip file created: {output_zip_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ea6dda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
